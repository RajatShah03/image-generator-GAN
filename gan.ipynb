{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb460cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, math, glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dad6e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants definition\n",
    "IMAGE_SIZE = (64, 64)\n",
    "N_CHANNELS = 3\n",
    "BATCH_SIZE = 4\n",
    "NUM_EXAMPLES = 1\n",
    "NORM_FACTOR = 255. / 2\n",
    "EPOCHS = 20\n",
    "LATENT_DIMS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbfb225a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2872 files belonging to 1 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_path = \"dataset\"\n",
    "\n",
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory=dataset_path, \n",
    "    image_size=IMAGE_SIZE,\n",
    "    seed=101,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29173232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "# plt.figure(figsize=(8, 8), dpi=100)\n",
    "# for (x, y) in train_ds.take(1):\n",
    "#     for i in range(6):\n",
    "#         plt.subplot(3, 3, i + 1)\n",
    "#         plt.imshow(x[i].numpy().astype('uint8'))\n",
    "#         plt.title(f'label: {y[i].numpy()} \\n shape: {x[i].numpy().shape}')\n",
    "#         plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dec87a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images\n",
    "def preprocess(data, label):\n",
    "    data = tf.image.resize(data, IMAGE_SIZE)\n",
    "    return ((data - NORM_FACTOR) / NORM_FACTOR, label)\n",
    "\n",
    "def deprocess(data):\n",
    "    return data * NORM_FACTOR + NORM_FACTOR\n",
    "\n",
    "train_ds = train_ds.map(preprocess).prefetch(1).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db613b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize preprocessed images\n",
    "# plt.figure(figsize=(6, 6), dpi=100)\n",
    "\n",
    "# for (x, y) in train_ds.take(1):\n",
    "#     for i in range(0, 6):\n",
    "#         img = x[i]\n",
    "#         label = y[i]\n",
    "#         plt.subplot(3, 3, i + 1)\n",
    "#         plt.imshow(deprocess(img.numpy()).astype(np.uint8))\n",
    "#         plt.title(f'label: {label}')\n",
    "#         plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ced6290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN model\n",
    "class GAN():\n",
    "    def __init__(self, latent_dims, input_shape, batch_size, training_size=None):\n",
    "        self.latent_dims = latent_dims\n",
    "        self.image_shape = input_shape\n",
    "        self.batch_size = batch_size\n",
    "        self.training_size = training_size\n",
    "        self.checkpoint_dir = 'training-checkpoints/abstract-art'\n",
    "        self.checkpoint_prefix = os.path.join(self.checkpoint_dir, \"ckpt\")\n",
    "        \n",
    "        self.cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        \n",
    "        self.generator_optimizer = keras.optimizers.Adam(3e-4)\n",
    "        self.discriminator_optimizer = keras.optimizers.Adam(3e-4)\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        self.discriminator = self.build_discriminator()\n",
    "    \n",
    "    def build_generator(self):\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Dense(16 * 16 * 1024, input_shape=(self.latent_dims, )),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.LeakyReLU(),\n",
    "            keras.layers.Reshape((16, 16, 1024)),\n",
    "            keras.layers.Conv2DTranspose(1024, (4, 4), strides=2, padding='same'),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.LeakyReLU(),\n",
    "            keras.layers.Conv2DTranspose(512, (4, 4), strides=2, padding='same'),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.LeakyReLU(),\n",
    "            keras.layers.Conv2DTranspose(512, (4, 4), strides=1, padding='same'),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.LeakyReLU(),\n",
    "            keras.layers.Conv2DTranspose(256, (4, 4), strides=1, padding='same'),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.LeakyReLU(),\n",
    "            keras.layers.Conv2DTranspose(3, (4, 4), strides=1, padding='same', activation='tanh')\n",
    "        ])\n",
    "        return model\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Conv2D(256, (4, 4), strides=1, padding='same', input_shape=self.image_shape),\n",
    "            keras.layers.LeakyReLU(),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.Conv2D(512, (4, 4), strides=1, padding='same'),\n",
    "            keras.layers.LeakyReLU(),\n",
    "            keras.layers.Dropout(0.3),\n",
    "            keras.layers.Conv2D(512, (4, 4), strides=2, padding='same'),\n",
    "            keras.layers.LeakyReLU(),\n",
    "            keras.layers.Dropout(0.3),\n",
    "            keras.layers.Conv2D(1024, (4, 4), strides=2, padding='same'),\n",
    "            keras.layers.LeakyReLU(),\n",
    "            keras.layers.Dropout(0.3),\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(1)\n",
    "        ])\n",
    "        return model\n",
    "    \n",
    "    def generator_loss(self, fakes):\n",
    "        return self.cross_entropy(tf.ones_like(fakes), fakes)\n",
    "    \n",
    "    def discriminator_loss(self, reals, fakes):\n",
    "        real_loss = self.cross_entropy(tf.ones_like(reals), reals)\n",
    "        fake_loss = self.cross_entropy(tf.zeros_like(fakes), fakes)\n",
    "        return real_loss + fake_loss\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, images):\n",
    "        noise = tf.random.normal(shape=(self.batch_size, self.latent_dims))\n",
    "        \n",
    "        with tf.GradientTape() as generator_tape, tf.GradientTape() as discriminator_tape:\n",
    "            generated_images = self.generator(noise, training=True)\n",
    "            \n",
    "            real_output = self.discriminator(images, training=True)\n",
    "            fake_output = self.discriminator(generated_images, training=True)\n",
    "            \n",
    "            generator_loss = self.generator_loss(fakes=fake_output)\n",
    "            discriminator_loss = self.discriminator_loss(reals=real_output, fakes=fake_output)\n",
    "            \n",
    "        generator_gradients = generator_tape.gradient(generator_loss, self.generator.trainable_variables)\n",
    "        discriminator_gradients = discriminator_tape.gradient(discriminator_loss, self.discriminator.trainable_variables)\n",
    "        \n",
    "        self.generator_optimizer.apply_gradients(zip(generator_gradients, self.generator.trainable_variables))\n",
    "        self.discriminator_optimizer.apply_gradients(zip(discriminator_gradients, self.discriminator.trainable_variables))\n",
    "    \n",
    "    def get_checkpoint_callback(self):\n",
    "        checkpoint = tf.train.Checkpoint(\n",
    "            generator_optimizer=self.generator_optimizer,\n",
    "            discriminator_optimizer=self.discriminator_optimizer,\n",
    "            generator=self.generator,\n",
    "            discriminator=self.discriminator\n",
    "        )\n",
    "        return checkpoint\n",
    "    \n",
    "    def train(self, dataset, epochs, seed, load_from_checkpoint=False):\n",
    "        start_training = time.time()\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            start = time.time()\n",
    "            for batch_idx, (image_batch, _) in enumerate(dataset):\n",
    "                self.train_step(image_batch)\n",
    "                self.generate_and_save(epoch, seed)\n",
    "                if self.training_size is not None:\n",
    "                    print(f'Batch: {batch_idx+1}/{math.ceil(self.training_size/self.batch_size)}')\n",
    "                else:\n",
    "                    print(f'Batch: {batch_idx+1}')\n",
    "            end = time.time()\n",
    "            print(f'Epoch: {epoch}/{epochs} | Time: {math.ceil(end - start)} seconds')\n",
    "        end_training = time.time()  \n",
    "        print(f'Training duration: {math.ceil(end_training - start_training)} seconds')\n",
    "        \n",
    "        self.generate_and_save(epochs, seed)\n",
    "        return True\n",
    "    \n",
    "    def generate_and_save(self, epoch, test):\n",
    "        generated_images = self.generator(test, training=False)\n",
    "        plt.figure(figsize=(4, 4), dpi=200)\n",
    "        for i in range(generated_images.shape[0]):\n",
    "            plt.imshow(deprocess(generated_images[i].numpy()).astype(np.uint8))\n",
    "            plt.axis('off')\n",
    "        plt.savefig(f'generated-images/abstract-art/image_at_epoch__{epoch}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1038f120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for generated images\n",
    "if not os.path.isdir('generated-images/abstract-art'):\n",
    "    os.mkdir('generated-images/abstract-art')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4084749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random starting seed\n",
    "seed = tf.random.normal([NUM_EXAMPLES, LATENT_DIMS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71dbf490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a GAN model\n",
    "gan = GAN(\n",
    "    latent_dims=LATENT_DIMS, \n",
    "    input_shape=IMAGE_SIZE + (N_CHANNELS, ), \n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40490afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 262144)            26476544  \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 262144)           1048576   \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 262144)            0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 16, 16, 1024)      0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 32, 32, 1024)     16778240  \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 1024)     4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 32, 32, 1024)      0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 64, 64, 512)      8389120   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64, 64, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 64, 64, 512)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 64, 64, 512)      4194816   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 64, 64, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 64, 64, 512)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 64, 64, 256)      2097408   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 64, 64, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 64, 64, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 64, 64, 3)        12291     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59,006,211\n",
      "Trainable params: 58,477,315\n",
      "Non-trainable params: 528,896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0140defe",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model=gan.generator, to_file='abstract-art-gan-generator.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a55f528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 64, 64, 256)       12544     \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 64, 64, 256)       0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64, 64, 256)       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 512)       2097664   \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 64, 64, 512)       0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64, 64, 512)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 512)       4194816   \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 32, 32, 512)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32, 32, 512)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 1024)      8389632   \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 16, 16, 1024)      0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16, 16, 1024)      0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 262144)            0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 262145    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,956,801\n",
      "Trainable params: 14,956,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb42dc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model=gan.discriminator, to_file='abstract-art-gan-discriminator.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e37c5be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1\n",
      "Batch: 2\n",
      "Batch: 3\n",
      "Batch: 4\n",
      "Batch: 5\n",
      "Batch: 6\n",
      "Batch: 7\n",
      "Batch: 8\n",
      "Batch: 9\n",
      "Batch: 10\n",
      "Batch: 11\n",
      "Batch: 12\n",
      "Batch: 13\n",
      "Batch: 14\n",
      "Batch: 15\n",
      "Batch: 16\n",
      "Batch: 17\n",
      "Batch: 18\n",
      "Batch: 19\n",
      "Batch: 20\n",
      "Batch: 21\n",
      "Batch: 22\n",
      "Batch: 23\n",
      "Batch: 24\n",
      "Batch: 25\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10160\\3221213879.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Train gan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10160\\4173130777.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, dataset, epochs, seed, load_from_checkpoint)\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_and_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_size\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Batch: {batch_idx+1}/{math.ceil(self.training_size/self.batch_size)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10160\\4173130777.py\u001b[0m in \u001b[0;36mgenerate_and_save\u001b[1;34m(self, epoch, test)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'generated-images/abstract-art/image_at_epoch__{epoch}.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-10\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1155\u001b[0m     \"\"\"\n\u001b[0;32m   1156\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1158\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-10\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1123\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1124\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train gan\n",
    "gan.train(dataset=train_ds, epochs=EPOCHS, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b849e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6ce23a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
