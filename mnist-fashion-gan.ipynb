{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6daf9ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, math, glob\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "700a8b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the MNIST fashion dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "589174be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess data\n",
    "def preprocess(data):\n",
    "    # Add channel axis\n",
    "    data = data[..., tf.newaxis]\n",
    "    # Normalize between [-1, 1]; due to tanh activation used\n",
    "    norm_factor = 255. / 2.\n",
    "    return (data - norm_factor) / norm_factor\n",
    "\n",
    "def deprocess(data):\n",
    "    norm_factor = 255. / 2.\n",
    "    return data * norm_factor + norm_factor\n",
    "\n",
    "x_train, x_test = preprocess(x_train), preprocess(x_test)\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49745f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data constants definition\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a097632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and shuffle dataset\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(x_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(buffer_size=BUFFER_SIZE).cache()\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(x_test).shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(buffer_size=BUFFER_SIZE).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21439398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN model\n",
    "class GAN():\n",
    "    def __init__(self, latent_dims, input_shape, batch_size):\n",
    "        self.latent_dims = latent_dims\n",
    "        self.image_shape = input_shape\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        \n",
    "        self.generator_optimizer = keras.optimizers.Adam(1e-4)\n",
    "        self.discriminator_optimizer = keras.optimizers.Adam(1e-4)\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        self.discriminator = self.build_discriminator()\n",
    "    \n",
    "    def build_generator(self):\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Dense(7*7*256, input_shape=(self.latent_dims, )),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.LeakyReLU(),\n",
    "            keras.layers.Reshape((7, 7, 256)),\n",
    "            keras.layers.Conv2DTranspose(128, (4, 4), strides=2, padding='same'),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.LeakyReLU(),\n",
    "            keras.layers.Conv2DTranspose(64, (4, 4), strides=1, padding='same'),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.LeakyReLU(),\n",
    "            keras.layers.Conv2DTranspose(1, (4, 4), strides=2, padding='same', activation='tanh')\n",
    "        ])\n",
    "        return model\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Conv2D(64, (4, 4), strides=1, padding='same', input_shape=self.image_shape),\n",
    "            keras.layers.LeakyReLU(),\n",
    "            keras.layers.Dropout(0.3),\n",
    "            keras.layers.Conv2D(128, (4, 4), strides=2, padding='same'),\n",
    "            keras.layers.LeakyReLU(),\n",
    "            keras.layers.Dropout(0.3),\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(1)\n",
    "        ])\n",
    "        return model\n",
    "    \n",
    "    def generator_loss(self, fakes):\n",
    "        return self.cross_entropy(tf.ones_like(fakes), fakes)\n",
    "    \n",
    "    def discriminator_loss(self, reals, fakes):\n",
    "        real_loss = self.cross_entropy(tf.ones_like(reals), reals)\n",
    "        fake_loss = self.cross_entropy(tf.zeros_like(fakes), fakes)\n",
    "        return real_loss + fake_loss\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, images):\n",
    "        noise = tf.random.normal(shape=(self.batch_size, self.latent_dims))\n",
    "        \n",
    "        with tf.GradientTape() as generator_tape, tf.GradientTape() as discriminator_tape:\n",
    "            generated_images = self.generator(noise, training=True)\n",
    "            \n",
    "            real_output = self.discriminator(images, training=True)\n",
    "            fake_output = self.discriminator(generated_images, training=True)\n",
    "            \n",
    "            generator_loss = self.generator_loss(fakes=fake_output)\n",
    "            discriminator_loss = self.discriminator_loss(reals=real_output, fakes=fake_output)\n",
    "            \n",
    "        generator_gradients = generator_tape.gradient(generator_loss, self.generator.trainable_variables)\n",
    "        discriminator_gradients = discriminator_tape.gradient(discriminator_loss, self.discriminator.trainable_variables)\n",
    "        \n",
    "        self.generator_optimizer.apply_gradients(zip(generator_gradients, self.generator.trainable_variables))\n",
    "        self.discriminator_optimizer.apply_gradients(zip(discriminator_gradients, self.discriminator.trainable_variables))\n",
    "    \n",
    "    def train(self, dataset, epochs, seed):\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            start = time.time()    \n",
    "            for image_batch in dataset:\n",
    "                self.train_step(image_batch)\n",
    "                self.generate_and_save(epoch, seed)\n",
    "            end = time.time()\n",
    "            print(f'Epoch: {epoch}/{epochs} | Time: {math.ceil(end - start)} seconds')\n",
    "        self.generate_and_save(epochs, seed, show=True)\n",
    "        return True\n",
    "    \n",
    "    def generate_and_save(self, epoch, test, show=False):\n",
    "        generated_images = self.generator(test, training=False)\n",
    "        \n",
    "        plt.figure(figsize=(4, 4), dpi=200)\n",
    "        \n",
    "        for i in range(generated_images.shape[0]):\n",
    "            plt.subplot(4, 4, i + 1)\n",
    "            plt.imshow(deprocess(generated_images[i, :, :, 0]), cmap='gray')\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.savefig(f'generated-images/image_at_epoch__{epoch}.png')\n",
    "        if show:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "600a0d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training constants definition\n",
    "EPOCHS = 30\n",
    "LATENT_DIMS = 100\n",
    "INPUT_SHAPE = (28, 28, 1)\n",
    "NUM_EXAMPLES = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfe2cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for generated images\n",
    "if not os.path.isdir('generated-images'):\n",
    "    os.mkdir('generated-images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7f64dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random starting seed\n",
    "seed = tf.random.normal([NUM_EXAMPLES, LATENT_DIMS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a9ab82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a GAN model\n",
    "gan = GAN(latent_dims=LATENT_DIMS, input_shape=INPUT_SHAPE, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e49a4222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12544)             1266944   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 12544)            50176     \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 12544)             0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 128)      524416    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 14, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 14, 14, 64)       131136    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        1025      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,974,465\n",
      "Trainable params: 1,948,993\n",
      "Non-trainable params: 25,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbfd57fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 64)        1088      \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 28, 28, 64)        0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 28, 28, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 128)       131200    \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 25089     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 157,377\n",
      "Trainable params: 157,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c7d08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train gan\n",
    "gan.train(dataset=train_ds, epochs=EPOCHS, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "def96064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\AppData\\Local\\Temp\\ipykernel_7176\\4130797846.py:8: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(filename)\n",
      "C:\\Users\\Rajat\\AppData\\Local\\Temp\\ipykernel_7176\\4130797846.py:10: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(filename)\n"
     ]
    }
   ],
   "source": [
    "# Create a gif with generated images\n",
    "gif_file = 'gan-fashion-mnist-generated.gif'\n",
    "\n",
    "with imageio.get_writer(gif_file, mode='I') as writer:\n",
    "  filenames = glob.glob('generated-images/image*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  for filename in filenames:\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "  image = imageio.imread(filename)\n",
    "  writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b546ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
